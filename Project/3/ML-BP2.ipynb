{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avinashk94/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# np.seterr(divide='ignore', invalid='ignore')\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainImages = mnist.train.images.T\n",
    "testImages = mnist.test.images.T\n",
    "trainLabels = mnist.train.labels.T\n",
    "testLabels = mnist.test.labels.T\n",
    "validationImages = mnist.validation.images.T\n",
    "validationLabels = mnist.validation.labels.T\n",
    "(nFeatures,m) = trainImages.shape\n",
    "\n",
    "meanImg = np.mean(trainImages,1)[:,np.newaxis]\n",
    "trainImages -= meanImg\n",
    "testImages -= meanImg\n",
    "validationImages -= meanImg\n",
    "\n",
    "\n",
    "batchSize = 100\n",
    "printEvery = 5\n",
    "nEpochs = 100\n",
    "nClasses = 10\n",
    "learningRate = 0.00005 #IF used....\n",
    "lambdaa = 0.01\n",
    "nH1 = 512\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.random.randn(nH1,nFeatures)\n",
    "b1 = np.zeros(nH1)\n",
    "\n",
    "W2 = np.random.randn(nClasses,nH1)\n",
    "b2 = np.zeros(nClasses)\n",
    "\n",
    "\n",
    "\n",
    "# z1 = W1.dot(trainImages) + b1[:,np.newaxis]\n",
    "# a1 = np.maximum(z1,0,z1)\n",
    "\n",
    "# z2 = W2.dot(a1) + b2[:,np.newaxis]\n",
    "# z2 -= np.max(z2)\n",
    "# z2Exp = np.exp(z2)\n",
    "# a2 = np.maximum(z1,0,z1)\n",
    "\n",
    "# loss = -np.sum(np.multiply(trainLabels,(z2-np.sum(z2Exp,0))),0)\n",
    "\n",
    "# dz2 = (z2Exp/np.sum(z2Exp,0))-trainLabels\n",
    "# dW2 = dz2.dot(a1.T)\n",
    "# db2 = np.sum(dz2,1)\n",
    "\n",
    "# da1 = W2.T.dot(dz2)\n",
    "# dz1 = np.zeros_like(da1)\n",
    "# dz1[da1>0] = 1\n",
    "\n",
    "# dW1 = dz1.dot(trainImages.T)\n",
    "# db1 = np.sum(dz1,1)\n",
    "# print(dW1.shape,db1.shape)\n",
    "\n",
    "\n",
    "# z = W.dot(trainImages) + b[:,np.newaxis]\n",
    "# z -= np.max(z)\n",
    "# zExp = np.exp(z)\n",
    "# zExp.shape\n",
    "# print(np.exp(np.max(z)))\n",
    "# print(np.max(zExp))\n",
    "\n",
    "# loss = -np.sum(np.multiply(trainLabels,(z-np.sum(zExp,0))),0)\n",
    "\n",
    "# dz = (zExp/np.sum(zExp,0))-trainLabels\n",
    "# dW = dz.dot(trainImages.T)\n",
    "# db = np.sum(dz,1)\n",
    "# np.max(z).shape\n",
    "\n",
    "# a = zExp/np.sum(zExp,0)\n",
    "# correct = np.sum(np.equal(np.argmax(a,0),np.argmax(trainLabels,0)))\n",
    "# print(np.max(z,0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findOut(x):\n",
    "    z1 = W1.dot(x) + b1[:,np.newaxis]\n",
    "    a1 = np.maximum(z1,0,z1)\n",
    "\n",
    "    z2 = W2.dot(a1) + b2[:,np.newaxis]\n",
    "    z2 -= np.max(z2,0)\n",
    "    z2Exp = np.exp(z2)\n",
    "    a = z2Exp/np.sum(z2Exp,0)\n",
    "#     print(a.shape)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 9135545.15355 0.131072727273 0.1286 0.1332\n",
      "Loss: 35136927.3216 0.365472727273 0.367 0.3648\n",
      "Loss: 27779450.8525 0.496636363636 0.4993 0.5146\n",
      "Loss: 9489169.59002 0.547781818182 0.554 0.5542\n",
      "Loss: 1676126.21617 0.764090909091 0.7724 0.7714\n",
      "Loss: 762070.536129 0.815454545455 0.8199 0.8268\n",
      "Loss: 527050.99472 0.783454545455 0.794 0.7886\n",
      "Loss: 377681.233728 0.766654545455 0.7768 0.7762\n",
      "Loss: 332367.883543 0.729418181818 0.7455 0.7414\n",
      "Loss: 252987.868553 0.718527272727 0.7316 0.737\n",
      "Loss: 219077.891389 0.700272727273 0.7137 0.719\n",
      "Loss: 183753.719096 0.681818181818 0.6976 0.7064\n",
      "Loss: 169545.470468 0.662563636364 0.6796 0.683\n",
      "Loss: 155505.447537 0.645981818182 0.6667 0.6656\n",
      "Loss: 150903.725102 0.630690909091 0.6452 0.6486\n",
      "Loss: 144552.637335 0.620945454545 0.6362 0.6374\n",
      "Loss: 143998.074341 0.612563636364 0.6314 0.6282\n",
      "Loss: 141480.240382 0.608272727273 0.6274 0.6306\n",
      "Loss: 141578.984108 0.607163636364 0.6255 0.63\n",
      "Loss: 140621.085509 0.605927272727 0.6269 0.6278\n",
      "Loss: 140275.096127 0.605818181818 0.6277 0.6286\n",
      "Loss: 138326.743356 0.606436363636 0.6259 0.6232\n",
      "Loss: 136055.401914 0.606763636364 0.6257 0.6242\n",
      "Loss: 134291.697924 0.609036363636 0.6247 0.6296\n",
      "Loss: 132846.976457 0.609745454545 0.6244 0.6292\n",
      "Loss: 131480.458261 0.610054545455 0.6262 0.6288\n",
      "Loss: 130255.426922 0.611854545455 0.6277 0.6296\n",
      "Loss: 129309.269697 0.613054545455 0.6286 0.629\n",
      "Loss: 128466.602383 0.6164 0.6367 0.63\n",
      "Loss: 127746.417206 0.617327272727 0.6373 0.6336\n",
      "Loss: 127087.706777 0.617418181818 0.6384 0.6318\n",
      "Loss: 126289.387434 0.617854545455 0.6386 0.6312\n",
      "Loss: 125415.718914 0.6172 0.638 0.6306\n",
      "Loss: 124287.831276 0.617872727273 0.6393 0.63\n",
      "Loss: 123171.67344 0.617636363636 0.6397 0.6324\n",
      "Loss: 121877.407083 0.617581818182 0.6397 0.635\n",
      "Loss: 120523.128003 0.617509090909 0.6396 0.6346\n",
      "Loss: 119125.382932 0.618381818182 0.64 0.6342\n",
      "Loss: 117598.787058 0.619054545455 0.639 0.6358\n",
      "Loss: 115954.344858 0.619454545455 0.6421 0.6348\n",
      "Loss: 114320.562206 0.619490909091 0.6419 0.6336\n",
      "Loss: 113293.248068 0.614163636364 0.6381 0.6316\n",
      "Loss: 115394.536027 0.611636363636 0.6353 0.6266\n",
      "Loss: 120041.692593 0.607763636364 0.6261 0.6176\n",
      "Loss: 108174.034145 0.615381818182 0.6418 0.6326\n",
      "Loss: 106132.069269 0.618 0.6422 0.631\n",
      "Loss: 104668.432995 0.615345454545 0.6398 0.6312\n",
      "Loss: 104537.570957 0.616927272727 0.6378 0.629\n",
      "Loss: 102816.575323 0.612781818182 0.6317 0.6224\n",
      "Loss: 102190.078719 0.611 0.631 0.6198\n",
      "Loss: 104493.240755 0.608981818182 0.6263 0.6146\n",
      "Loss: 98590.7588225 0.613545454545 0.6351 0.6228\n",
      "Loss: 97744.5160116 0.614236363636 0.6327 0.621\n",
      "Loss: 96855.2830728 0.613836363636 0.6336 0.6224\n",
      "Loss: 96203.8439486 0.612163636364 0.6284 0.6148\n",
      "Loss: 95558.0032689 0.609145454545 0.6298 0.616\n",
      "Loss: 95373.5640613 0.607418181818 0.625 0.613\n",
      "Loss: 95315.6131947 0.604490909091 0.6245 0.6088\n",
      "Loss: 94857.0789132 0.602963636364 0.6227 0.609\n",
      "Loss: 95197.1118986 0.602327272727 0.6226 0.6064\n",
      "Loss: 93650.0560231 0.601309090909 0.6218 0.6068\n",
      "Loss: 94705.7165018 0.601654545455 0.622 0.6066\n",
      "Loss: 93921.3054095 0.593 0.6132 0.598\n",
      "Loss: 101266.238415 0.593018181818 0.6133 0.5992\n",
      "Loss: 106209.006514 0.585709090909 0.6051 0.5944\n",
      "Loss: 154241.128082 0.576581818182 0.5971 0.5822\n",
      "Loss: 396485.982275 0.540054545455 0.5514 0.5478\n",
      "Loss: 712958.264636 0.533363636364 0.5492 0.535\n",
      "Loss: 1347499.23941 0.519418181818 0.5336 0.5292\n",
      "Loss: 201682.962419 0.574436363636 0.5935 0.5806\n",
      "Loss: 158018.442427 0.579472727273 0.602 0.589\n",
      "Loss: 145010.431256 0.578072727273 0.6018 0.5862\n",
      "Loss: 138365.746098 0.574418181818 0.5982 0.5798\n",
      "Loss: 133659.218076 0.572290909091 0.5966 0.576\n",
      "Loss: 130786.755938 0.568563636364 0.5942 0.573\n",
      "Loss: 128870.6184 0.565363636364 0.5902 0.5696\n",
      "Loss: 128753.096464 0.562127272727 0.5872 0.5674\n",
      "Loss: 127909.25846 0.559272727273 0.5844 0.5668\n",
      "Loss: 129108.345558 0.556436363636 0.5821 0.5638\n",
      "Loss: 128885.577689 0.552036363636 0.5778 0.5638\n",
      "Loss: 129285.947511 0.553290909091 0.5766 0.5576\n",
      "Loss: 127914.082848 0.548963636364 0.5761 0.5554\n",
      "Loss: 128394.545568 0.549745454545 0.573 0.5532\n",
      "Loss: 126256.866732 0.545981818182 0.5741 0.5532\n",
      "Loss: 126025.839823 0.546981818182 0.5685 0.5508\n",
      "Loss: 124064.446225 0.543654545455 0.5706 0.5504\n",
      "Loss: 124453.046196 0.5436 0.5648 0.5492\n",
      "Loss: 123152.349911 0.541581818182 0.5676 0.5498\n",
      "Loss: 124016.339625 0.540581818182 0.5623 0.5484\n",
      "Loss: 123187.290984 0.538090909091 0.564 0.546\n",
      "Loss: 126166.397827 0.534527272727 0.5559 0.538\n",
      "Loss: 125149.494025 0.533745454545 0.5577 0.539\n",
      "Loss: 127389.629688 0.532763636364 0.5532 0.5334\n",
      "Loss: 126912.595673 0.534654545455 0.5575 0.538\n",
      "Loss: 125773.323098 0.528709090909 0.5486 0.5298\n",
      "Loss: 122655.432819 0.533909090909 0.5543 0.535\n",
      "Loss: 117810.474218 0.531181818182 0.5519 0.5328\n",
      "Loss: 113237.82443 0.533890909091 0.5552 0.5346\n",
      "Loss: 109473.614229 0.532 0.5515 0.534\n",
      "Loss: 106212.910171 0.532090909091 0.5523 0.534\n"
     ]
    }
   ],
   "source": [
    "for _ in range(nEpochs):\n",
    "    loss = 0.0\n",
    "    #Forward....\n",
    "    z1 = W1.dot(trainImages) + b1[:,np.newaxis]\n",
    "    a1 = np.maximum(z1,0,z1)\n",
    "    \n",
    "    z2 = W2.dot(a1) + b2[:,np.newaxis]\n",
    "    z2 -= np.max(z2,0)\n",
    "    z2Exp = np.exp(z2)\n",
    "#     z2Exp[z2Exp<=0] = 1e-10\n",
    "    loss = -np.sum(np.multiply(trainLabels,z2-np.log(np.sum(z2Exp,0))),0) \n",
    "    \n",
    "#     print(np.equal(np.argmax(findOut(testImages),0),np.argmax(testLabels,0)).shape)\n",
    "    correct1 = np.sum(np.equal(np.argmax(findOut(trainImages),0),np.argmax(trainLabels,0)))/m\n",
    "    correct2 = np.sum(np.equal(np.argmax(findOut(testImages),0),np.argmax(testLabels,0)))/testLabels.shape[1]\n",
    "    correct3 = np.sum(np.equal(np.argmax(findOut(validationImages),0),np.argmax(validationLabels,0)))/validationLabels.shape[1]\n",
    "    print('Loss:',np.sum(loss), correct1, correct2, correct3)\n",
    "    \n",
    "    #Backward\n",
    "    dz2 = (z2Exp/np.sum(z2Exp,0))-trainLabels\n",
    "#     print(np.sum(dz2))\n",
    "    dW2 = dz2.dot(a1.T)\n",
    "    db2 = np.sum(dz2,1)\n",
    "\n",
    "    da1 = W2.T.dot(dz2)\n",
    "    dz1 = np.zeros_like(da1)\n",
    "    dz1[da1>0] = 1\n",
    "\n",
    "    dW1 = dz1.dot(trainImages.T)\n",
    "    db1 = np.sum(dz1,1)\n",
    "    \n",
    "    W2 = W2 - learningRate*dW2 - lambdaa*W2\n",
    "    b2 = b2 - learningRate*db2\n",
    "    W1 = W1 - learningRate*dW1 - lambdaa*W1\n",
    "    b1 = b1 - learningRate*db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
