{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import model_selection\n",
    "from PIL import Image\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from scipy import ndimage, misc\n",
    "import glob\n",
    "import pickle\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('files/Anno/list_attr_celeba.txt', delim_whitespace = True, header=1)\n",
    "df = data['Eyeglasses']\n",
    "df = (df + 1)/2\n",
    "d = np.eye(2)[df.values.astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "usingImages = 10000\n",
    "nClasses = 2\n",
    "shape1 = 178\n",
    "shape2 = 218\n",
    "printEvery = 1\n",
    "batchSize = 100\n",
    "lambdaa = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array([np.float32(np.array(Image.open(\"files/Img/img_align_celeba/\"+str(fname)).resize((shape1, shape2))))/256 for fname in df.head(usingImages).index])\n",
    "with open('my.pickle', 'wb') as handle:\n",
    "    pickle.dump(images, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('my.pickle', 'rb') as handle:\n",
    "    images = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(images, d[:usingImages], test_size=0.05, shuffle=False)\n",
    "X_validate, X_test, y_validate, y_test = model_selection.train_test_split(X_test, y_test, test_size=0.50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, shape2, shape1, 3])\n",
    "t = tf.placeholder(tf.float32, [None,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutionalNeuralNetwork(x):\n",
    "    weights = {'conv1':tf.Variable(tf.random_normal([5,5,3,64])),\n",
    "               'conv2':tf.Variable(tf.random_normal([5,5,64,128])),\n",
    "               'conv3':tf.Variable(tf.random_normal([5,5,128,256])),\n",
    "               'conv4':tf.Variable(tf.random_normal([5,5,256,256])),\n",
    "               'fullyC1':tf.Variable(tf.random_normal([14*12*256,1024])),\n",
    "               'fullyC2':tf.Variable(tf.random_normal([1024,1024])),\n",
    "               'out':tf.Variable(tf.random_normal([1024,nClasses]))}\n",
    "    \n",
    "    biases = {'conv1':tf.Variable(tf.random_normal([64])),\n",
    "              'conv2':tf.Variable(tf.random_normal([128])),\n",
    "              'conv3':tf.Variable(tf.random_normal([256])),\n",
    "              'conv4':tf.Variable(tf.random_normal([256])),\n",
    "              'fullyC1':tf.Variable(tf.random_normal([1024])),\n",
    "              'fullyC2':tf.Variable(tf.random_normal([1024])),\n",
    "              'out':tf.Variable(tf.random_normal([nClasses]))}\n",
    "\n",
    "    conv1 = tf.nn.relu(tf.nn.conv2d(input=x, filter=weights['conv1'],strides=[1,1,1,1],padding='SAME')+ biases['conv1'])\n",
    "    conv1 = tf.nn.max_pool(conv1,ksize=[1,2,2,1] ,strides=[1,2,2,1], padding='SAME')\n",
    "    print(conv1)\n",
    "    \n",
    "    conv2 = tf.nn.relu(tf.nn.conv2d(input=conv1, filter=weights['conv2'],strides=[1,1,1,1],padding='SAME') + biases['conv2'])\n",
    "    conv2 = tf.nn.max_pool(conv2,ksize=[1,2,2,1] ,strides=[1,2,2,1], padding='SAME')\n",
    "    print(conv2)\n",
    "    \n",
    "    conv3 = tf.nn.relu(tf.nn.conv2d(input=conv2, filter=weights['conv3'],strides=[1,1,1,1],padding='SAME') + biases['conv3'])\n",
    "    conv3 = tf.nn.max_pool(conv3,ksize=[1,2,2,1] ,strides=[1,2,2,1], padding='SAME')\n",
    "    print(conv3)\n",
    "    \n",
    "    conv4 = tf.nn.relu(tf.nn.conv2d(input=conv3, filter=weights['conv4'],strides=[1,1,1,1],padding='SAME') + biases['conv4'])\n",
    "    conv4 = tf.nn.max_pool(conv4,ksize=[1,2,2,1] ,strides=[1,2,2,1], padding='SAME')\n",
    "    print(conv4)\n",
    "    \n",
    "    conv4 = tf.reshape(conv4,[-1,14*12*256])\n",
    "    print(conv4)\n",
    "    fcLayer1 = tf.nn.relu(tf.matmul(conv4,weights['fullyC1']) + biases['fullyC1'])\n",
    "    print(fcLayer1)\n",
    "    fcLayer1 = tf.nn.dropout(fcLayer1,keepRate)\n",
    "    fcLayer2 = tf.nn.relu(tf.matmul(fcLayer1,weights['fullyC2']) + biases['fullyC2'])\n",
    "    output = tf.matmul(fcLayer2,weights['out']) + biases['out']\n",
    "    print(output)\n",
    "    \n",
    "    regLoss = tf.nn.l2_loss(weights['conv1']) + tf.nn.l2_loss(weights['conv2']) + tf.nn.l2_loss(weights['conv3']) + tf.nn.l2_loss(weights['conv3']) + tf.nn.l2_loss(weights['fullyC1']) + tf.nn.l2_loss(weights['fullyC1']) + tf.nn.l2_loss(weights['out'])\n",
    "    return output, regLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNetwork():\n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=tf.transpose(y),labels=tf.transpose(t)) + lambdaa*regLoss)\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "    correct = tf.equal(tf.argmax(y),tf.argmax(t))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,'float'))\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(nEpochs):\n",
    "        error = 0.0\n",
    "        for i in range(int(usingImages*0.8/batchSize)):\n",
    "            xs = X_train[i*batchSize:(i+1)*batchSize]\n",
    "            ys = y_train[i*batchSize:(i+1)*batchSize]\n",
    "            _, er = sess.run([optimizer,loss],feed_dict={x:xs,t:ys})\n",
    "            error += er\n",
    "        if (epoch+1)%printEvery == 0:\n",
    "            print('Loss in ',epoch+1,' epoch is ',error/(usingImages*8))\n",
    "\n",
    "    prediction = tf.equal(tf.argmax(y),tf.argmax(t))\n",
    "    accuracy = tf.reduce_mean(tf.cast(prediction,\"float\"))\n",
    "    print(\"Accuracy validation:\", sess.run(accuracy,{x: X_validate, t: y_validate}))\n",
    "    print(\"Accuracy Test:\", sess.run(accuracy,{x: X_test, t: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool:0\", shape=(?, 109, 89, 64), dtype=float32)\n",
      "Tensor(\"MaxPool_1:0\", shape=(?, 55, 45, 128), dtype=float32)\n",
      "Tensor(\"MaxPool_2:0\", shape=(?, 28, 23, 256), dtype=float32)\n",
      "Tensor(\"MaxPool_3:0\", shape=(?, 14, 12, 256), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(?, 43008), dtype=float32)\n",
      "Tensor(\"Relu_4:0\", shape=(?, 1024), dtype=float32)\n",
      "Tensor(\"add_6:0\", shape=(?, 2), dtype=float32)\n",
      "Y:::::: Tensor(\"add_6:0\", shape=(?, 2), dtype=float32)\n",
      "Tensor(\"Placeholder_1:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "nEpochs = 20\n",
    "keepRate = 0.8\n",
    "start_time = time.time()\n",
    "y, regLoss = convolutionalNeuralNetwork(x)\n",
    "print(\"Y::::::\",y)\n",
    "print(t)\n",
    "trainNetwork()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
