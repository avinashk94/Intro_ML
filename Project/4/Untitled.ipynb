{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avinashk94/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn import model_selection\n",
    "from PIL import Image\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from scipy import ndimage, misc\n",
    "import glob\n",
    "import pickle\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('files/Anno/list_attr_celeba.txt', delim_whitespace = True, header=1)\n",
    "df = data['Eyeglasses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202599,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usingImages = 4000\n",
    "nClasses= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array([np.array(Image.open(\"files/Img/img_align_celeba/\"+str(fname))) for fname in df.head(usingImages).index])\n",
    "images = np.float32(images)/256\n",
    "with open('my.pickle', 'wb') as handle:\n",
    "    pickle.dump(images, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('my.pickle', 'rb') as handle:\n",
    "    images = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(images, df.head(usingImages), test_size=0.20, shuffle=False)\n",
    "X_validate, X_test, y_validate, y_test = model_selection.train_test_split(X_test, y_test, test_size=0.50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(usingImages).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 218, 178, 3])\n",
    "t = tf.placeholder(tf.float32, [None,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolve2D(x,W):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maxpool2d(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1] ,strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolutionalNeuralNetwork(x):\n",
    "    weights = {'conv1':tf.Variable(tf.random_normal([5,5,3,64])),\n",
    "               'conv2':tf.Variable(tf.random_normal([5,5,64,64])),\n",
    "               'fullyC1':tf.Variable(tf.random_normal([7*7*64,1024])),\n",
    "               'fullyC2':tf.Variable(tf.random_normal([1024,1024])),\n",
    "               'out':tf.Variable(tf.random_normal([1024,nClasses]))}\n",
    "    \n",
    "    biases = {'conv1':tf.Variable(tf.random_normal([64])),\n",
    "              'conv2':tf.Variable(tf.random_normal([64])),\n",
    "              'fullyC1':tf.Variable(tf.random_normal([1024])),\n",
    "              'fullyC2':tf.Variable(tf.random_normal([1024])),\n",
    "              'out':tf.Variable(tf.random_normal([nClasses]))}\n",
    "    \n",
    "#     x = tf.transpose(x)\n",
    "    \n",
    "#     Img = tf.reshape(x,[-1,28,28,1])\n",
    "    \n",
    "    conv1 = tf.nn.relu(convolve2D(x,weights['conv1']) + biases['conv1'])\n",
    "    conv1 = maxpool2d(conv1)\n",
    "    print(conv1)\n",
    "    \n",
    "    conv2 = tf.nn.relu(convolve2D(conv1,weights['conv2']) + biases['conv2'])\n",
    "#     print(conv2)\n",
    "    conv2 = maxpool2d(conv2)\n",
    "    print(conv2)\n",
    "    \n",
    "    conv2 = tf.reshape(conv2,[-1,7*7*64])\n",
    "#     print(conv2)\n",
    "    fcLayer1 = tf.nn.relu(tf.matmul(conv2,weights['fullyC1']) + biases['fullyC1'])\n",
    "#     print(fcLayer1)\n",
    "    fcLayer1 = tf.nn.dropout(fcLayer1,keepRate)\n",
    "    fcLayer2 = tf.nn.relu(tf.matmul(fcLayer1,weights['fullyC2']) + biases['fullyC2'])\n",
    "    output = tf.matmul(fcLayer2,weights['out']) + biases['out']\n",
    "    print(output)\n",
    "    \n",
    "    regLoss = tf.nn.l2_loss(weights['conv1']) + tf.nn.l2_loss(weights['conv2']) + tf.nn.l2_loss(weights['fullyC1']) + tf.nn.l2_loss(weights['fullyC1']) + tf.nn.l2_loss(weights['out'])\n",
    "    return tf.transpose(output), regLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainNetwork():\n",
    "    with tf.name_scope(\"loss\") as scope:\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=tf.transpose(y),labels=tf.transpose(t)) + lambdaa*regLoss)\n",
    "        tf.summary.scalar(\"loss\",loss)\n",
    "    \n",
    "    with tf.name_scope(\"training\") as scope:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learningRate).minimize(loss)\n",
    "    \n",
    "    with tf.name_scope(\"accuracy\") as scope:\n",
    "        correct = tf.equal(tf.argmax(y),tf.argmax(t))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct,'float'))\n",
    "        \n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    mergeSummary = tf.summary.merge_all()\n",
    "\n",
    "    sess.run(init)\n",
    "    summaryWriter = tf.summary.FileWriter('../../TFout/2', sess.graph)\n",
    "\n",
    "    for epoch in range(nEpochs):\n",
    "        error = 0.0\n",
    "        for i in range(int(m/batchSize)):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batchSize)\n",
    "            _, er, summaryStr = sess.run([optimizer,loss,mergeSummary],feed_dict={x:batch_xs.T,t:batch_ys.T})\n",
    "            summaryWriter.add_summary(summaryStr, epoch*(int(m/batchSize)) + i)\n",
    "            error += er\n",
    "        if (epoch+1)%printEvery == 0:\n",
    "            print('Loss in ',epoch+1,' epoch is ',error)\n",
    "\n",
    "    prediction = tf.equal(tf.argmax(y),tf.argmax(t))\n",
    "    accuracy = tf.reduce_mean(tf.cast(prediction,\"float\"))\n",
    "    print(\"Accuracy Train:\", sess.run(accuracy,{x: trainImages, t: trainLabels}))\n",
    "    print(\"Accuracy validation:\", sess.run(accuracy,{x: validationImages, t: validationLabels}))\n",
    "    print(\"Accuracy Test:\", sess.run(accuracy,{x: testImages, t: testLabels}))\n",
    "    print(\"USPS Test Accuracy:\", sess.run(accuracy,{x: uspsImages, t: uspsLabels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool:0\", shape=(800, 109, 89, 64), dtype=float32)\n",
      "Tensor(\"MaxPool_1:0\", shape=(800, 55, 45, 64), dtype=float32)\n"
     ]
    },
   ],
   "source": [
    "nEpochs = 2\n",
    "keepRate = 0.8\n",
    "start_time = time.time()\n",
    "y, regLoss = convolutionalNeuralNetwork(X_train)\n",
    "trainNetwork()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
